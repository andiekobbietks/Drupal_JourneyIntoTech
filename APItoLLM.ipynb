{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP1vF7gww1bhE2/VU6gIa0W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andiekobbietks/Drupal_JourneyIntoTech/blob/main/APItoLLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8YOAPnByUOn",
        "outputId": "542f4ee6-3bce-45f8-edd5-fe0e27b5c90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0>>> Downloading ollama...\n",
            "100 10044    0 10044    0     0  25230      0 --:--:-- --:--:-- --:--:-- 25236\n",
            "############################################################################################# 100.0%\n",
            ">>> Installing ollama to /usr/local/bin...\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "# Download and install ollama to the system\n",
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install aiohttp pyngrok\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "\n",
        "# Set LD_LIBRARY_PATH so the system NVIDIA library\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "\n",
        "async def run_process(cmd):\n",
        "  print('>>> starting', *cmd)\n",
        "  p = await asyncio.subprocess.create_subprocess_exec(\n",
        "      *cmd,\n",
        "      stdout=asyncio.subprocess.PIPE,\n",
        "      stderr=asyncio.subprocess.PIPE,\n",
        "  )\n",
        "\n",
        "  async def pipe(lines):\n",
        "    async for line in lines:\n",
        "      print(line.strip().decode('utf-8'))\n",
        "\n",
        "  await asyncio.gather(\n",
        "      pipe(p.stdout),\n",
        "      pipe(p.stderr),\n",
        "  )\n",
        "\n",
        "#register an account at ngrok.com and create an authtoken and place it here\n",
        "await asyncio.gather(\n",
        "    run_process(['ngrok', 'config', 'add-authtoken','2eD0FCnpY3vJnaneE6FGFcECqgG_7MkmoUoP8EqC9AD8oAgZh'])\n",
        ")\n",
        "\n",
        "await asyncio.gather(\n",
        "    run_process(['ollama', 'serve']),\n",
        "    run_process(['ngrok', 'http', '--log', 'stderr', '11434']),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erat-YBlzEph",
        "outputId": "1957fda0-6edd-4fbd-e2aa-a5d65535f5d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (3.9.3)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp) (4.0.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp) (3.6)\n",
            ">>> starting ngrok config add-authtoken 2eD0FCnpY3vJnaneE6FGFcECqgG_7MkmoUoP8EqC9AD8oAgZh\n",
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            ">>> starting ollama serve\n",
            ">>> starting ngrok http --log stderr 11434\n",
            "Couldn't find '/root/.ollama/id_ed25519'. Generating new private key.\n",
            "Your new public key is:\n",
            "\n",
            "ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAIC/P/25Ar6JH1E6ocfdjPk6kuq0ngPg5t/fd/SeeTScs\n",
            "\n",
            "time=2024-03-26T03:30:14.761Z level=INFO source=images.go:806 msg=\"total blobs: 0\"\n",
            "time=2024-03-26T03:30:14.761Z level=INFO source=images.go:813 msg=\"total unused blobs removed: 0\"\n",
            "time=2024-03-26T03:30:14.762Z level=INFO source=routes.go:1110 msg=\"Listening on 127.0.0.1:11434 (version 0.1.29)\"\n",
            "time=2024-03-26T03:30:14.763Z level=INFO source=payload_common.go:112 msg=\"Extracting dynamic libraries to /tmp/ollama2986049038/runners ...\"\n",
            "t=2024-03-26T03:30:14+0000 lvl=info msg=\"no configuration paths supplied\"\n",
            "t=2024-03-26T03:30:14+0000 lvl=info msg=\"using configuration at default config path\" path=/root/.config/ngrok/ngrok.yml\n",
            "t=2024-03-26T03:30:14+0000 lvl=info msg=\"open config file\" path=/root/.config/ngrok/ngrok.yml err=nil\n",
            "t=2024-03-26T03:30:14+0000 lvl=warn msg=\"can't bind default web address, trying alternatives\" obj=web addr=127.0.0.1:4040\n",
            "t=2024-03-26T03:30:15+0000 lvl=info msg=\"starting web service\" obj=web addr=127.0.0.1:4041 allow_hosts=[]\n",
            "t=2024-03-26T03:30:15+0000 lvl=info msg=\"client session established\" obj=tunnels.session\n",
            "t=2024-03-26T03:30:15+0000 lvl=info msg=\"tunnel session started\" obj=tunnels.session\n",
            "t=2024-03-26T03:30:15+0000 lvl=info msg=\"started tunnel\" obj=tunnels name=command_line addr=http://localhost:11434 url=https://8553-34-16-196-206.ngrok-free.app\n",
            "time=2024-03-26T03:30:19.918Z level=INFO source=payload_common.go:139 msg=\"Dynamic LLM libraries [rocm_v60000 cpu_avx2 cpu cpu_avx cuda_v11]\"\n",
            "time=2024-03-26T03:30:19.918Z level=INFO source=gpu.go:77 msg=\"Detecting GPU type\"\n",
            "time=2024-03-26T03:30:19.918Z level=INFO source=gpu.go:191 msg=\"Searching for GPU management library libnvidia-ml.so\"\n",
            "time=2024-03-26T03:30:19.938Z level=INFO source=gpu.go:237 msg=\"Discovered GPU libraries: [/usr/lib64-nvidia/libnvidia-ml.so.535.104.05]\"\n",
            "time=2024-03-26T03:30:19.947Z level=INFO source=gpu.go:82 msg=\"Nvidia GPU detected\"\n",
            "time=2024-03-26T03:30:19.947Z level=INFO source=cpu_common.go:11 msg=\"CPU has AVX2\"\n",
            "time=2024-03-26T03:30:19.953Z level=INFO source=gpu.go:119 msg=\"CUDA Compute Capability detected: 7.5\"\n",
            "t=2024-03-26T03:30:52+0000 lvl=info msg=\"join connections\" obj=join id=e7c6fb4e50af l=127.0.0.1:11434 r=80.3.198.118:55436\n",
            "[GIN] 2024/03/26 - 03:30:52 | 403 |      38.226µs |    80.3.198.118 | GET      \"/\"\n",
            "t=2024-03-26T03:33:45+0000 lvl=info msg=\"join connections\" obj=join id=f5e07d98bfa2 l=127.0.0.1:11434 r=167.172.62.170:33184\n",
            "[GIN] 2024/03/26 - 03:33:45 | 403 |      27.807µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:33:45+0000 lvl=info msg=\"join connections\" obj=join id=0e475ed5a236 l=127.0.0.1:11434 r=167.172.62.170:33194\n",
            "[GIN] 2024/03/26 - 03:33:45 | 403 |      24.061µs |  167.172.62.170 | GET      \"//api/version\"\n",
            "t=2024-03-26T03:37:16+0000 lvl=info msg=\"join connections\" obj=join id=8378dbebc6d8 l=127.0.0.1:11434 r=167.172.62.170:49380\n",
            "[GIN] 2024/03/26 - 03:37:16 | 403 |      33.292µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:37:16+0000 lvl=info msg=\"join connections\" obj=join id=fb295d36a9ee l=127.0.0.1:11434 r=167.172.62.170:49396\n",
            "[GIN] 2024/03/26 - 03:37:16 | 403 |      24.018µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:37:16+0000 lvl=info msg=\"join connections\" obj=join id=5969e6408507 l=127.0.0.1:11434 r=167.172.62.170:49402\n",
            "[GIN] 2024/03/26 - 03:37:16 | 403 |       36.58µs |  167.172.62.170 | GET      \"//api/version\"\n",
            "t=2024-03-26T03:37:24+0000 lvl=info msg=\"join connections\" obj=join id=94df22f99272 l=127.0.0.1:11434 r=167.172.62.170:49414\n",
            "[GIN] 2024/03/26 - 03:37:24 | 403 |      23.561µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:37:24+0000 lvl=info msg=\"join connections\" obj=join id=163c36fc9516 l=127.0.0.1:11434 r=167.172.62.170:49430\n",
            "[GIN] 2024/03/26 - 03:37:24 | 403 |      24.619µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:38:44+0000 lvl=info msg=\"join connections\" obj=join id=4934da84603b l=127.0.0.1:11434 r=167.172.62.170:33048\n",
            "[GIN] 2024/03/26 - 03:38:44 | 403 |      31.446µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:38:44+0000 lvl=info msg=\"join connections\" obj=join id=b9bb17a1e74f l=127.0.0.1:11434 r=167.172.62.170:33060\n",
            "[GIN] 2024/03/26 - 03:38:44 | 403 |      23.429µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:38:45+0000 lvl=info msg=\"join connections\" obj=join id=3ffe2b76805c l=127.0.0.1:11434 r=167.172.62.170:33072\n",
            "[GIN] 2024/03/26 - 03:38:45 | 403 |      25.166µs |  167.172.62.170 | GET      \"//api/version\"\n",
            "t=2024-03-26T03:38:45+0000 lvl=info msg=\"join connections\" obj=join id=aed441c4fd64 l=127.0.0.1:11434 r=167.172.62.170:33084\n",
            "[GIN] 2024/03/26 - 03:38:45 | 403 |      23.785µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:38:50+0000 lvl=info msg=\"join connections\" obj=join id=e8f341f87c83 l=127.0.0.1:11434 r=167.172.62.170:35972\n",
            "[GIN] 2024/03/26 - 03:38:50 | 403 |      32.756µs |  167.172.62.170 | GET      \"//api/tags\"\n",
            "t=2024-03-26T03:38:51+0000 lvl=info msg=\"join connections\" obj=join id=91909c54b0f3 l=127.0.0.1:11434 r=167.172.62.170:35984\n",
            "[GIN] 2024/03/26 - 03:38:51 | 403 |      26.031µs |  167.172.62.170 | GET      \"//api/tags\"\n"
          ]
        }
      ]
    }
  ]
}